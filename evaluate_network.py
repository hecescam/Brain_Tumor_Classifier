# -*- coding: utf-8 -*-
"""evaluate_network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tuIXzYTl1bFld43eLKaIYnIijzFIwbK5

#Librería con diferentes funciones para observar el funcionamiento de la red neuronal.
"""

import tensorflow as tf
from keras.models import Model
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import cv2
import imutils
from keras import backend as K

"""#######################################################################################################


Función 'show_classified_image()': 

Muestra la clasificación de un ejemplo concreto

* Argumentos:
      - model:  modelo entrenado
      - image: imagen para clasificar
      - dict_indices: diccionario (key='nombre clase' , value='numero codificado')
      - true_class: clase real a la que pertenece la imagen
"""

def show_classified_image(model,image,dict_indices,true_class):

  plt.imshow(image, cmap='jet')
  plt.axis("off")
  print(".Real Class:", true_class)

  probs = model.predict(np.expand_dims(image, axis=0))#obtenemos las predicciones

  for key in dict_indices:#recorremos el diccionario con las clases

    p=probs[0][dict_indices[key]]#obtenemoms lo que es la lista de las predicciones y de la lista el valor correspondiente a la clase
    print(" - Probability of {0} : {1:2.1f}%".format(key,100*p))

"""#######################################################################################################


Función 'show_shape_weights()': 

Muestra los pesos de todas las capas de una red

* Argumentos:
      - weights:  pesos de la red neuronal (model.get_weights())
"""

def show_shape_weights(weights):

  print('SHAPE WEIGHTS: ',np.shape(weights),'\n')
  for i in range(len(weights)):
    print('shape of weights[%d]: ' % i, np.shape(weights[i]))

"""#######################################################################################################


Función 'show_weights_layer()': 

Muestra los pesos de los kernels de una capa

* Argumentos:
      - weights:  pesos de la red neuronal (model.get_weights())
      - nlayer: numero de la capa de la cual queremos ver los pesos
"""

def show_weights_layer(weights,nlayer):

 #elegimos la capa de la cual queremos ver los filtros(en la posicion 0 estan los pesos de la primera capa convolucional)

  nfilters = weights[nlayer].shape[3]#en la ultima posicion tenemos el numero de filtros
  ncols = 7 # número de columnas en la figura

  ma = abs(weights[nlayer]).max()#valor del peso maximo en tamaño absoluto
  nrows = int(np.ceil(nfilters/ncols)) # número de filas en la figura (redondea al valor mayor la division)
  fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15,15*nrows/ncols))
  axes_r = axes.ravel()

  for i in range(nfilters):#recorremos los filtros
    kernel = weights[nlayer][:,:,2,i]#aqui obtenemos un array con los pesos de tamaño del kernel (3x3 por ejemplo)
    ax = axes_r[i]
    ax.imshow(kernel, vmin=-ma, vmax=ma, cmap='bwr')
    ax.set_xticks([]); ax.set_yticks([])
    ax.set_title('weights kernel %d' % i, fontsize=10)
    
  for i in range(nfilters,nrows*ncols):
    fig.delaxes(axes_r[i])

"""#######################################################################################################


Función 'build_model_intermediate()': 

Crea un modelo intermedio

* Argumentos:
      - model:  modelo entrenado del cual obtener el modelo intermedio
      - nlayer: numero de la capa por la cual partir el modelo (será la capa final del modelo intermedio)
      - input_layer: booleano que indica si en el modelo original existe una capa input

* Devolución:
      - intermediate_model:  modelo intermedio cosntruido
"""

def build_model_intermediate(model,nlayer,input_layer=True):

  if input_layer:
    start=1
  else:
    start=0

  layer_outputs = [layer.output for layer in model.layers[start:nlayer+1]]
  
  intermediate_model = Model(inputs=model.input, outputs=layer_outputs)

  return intermediate_model

"""#######################################################################################################


Función 'show_output_first_convlayer()': 

Muestra las salidas de la primera capa convolucional de una ejemplo concreto

* Argumentos:
      - model:  modelo intermedio donde la capa de slaida es la primera capa convolucional del modelo original
      - image: una única imagen de un conjunto
      - activations: las activaciones que nos devuelve el model.predict() del modelo intermedio
"""

def show_output_first_convlayer(model,image,activations):

  plt.figure(figsize=(3,3))
  plt.imshow(image, cmap='gray')
  plt.title('input image', size=12)
  plt.xticks(())
  plt.yticks(())
  plt.show()

  print("\nOutputs layer "+model.layers[-1].name, activations.shape,"\n")

  noutputs = activations.shape[-1]
  ncols = 4
  nrows = int(np.ceil(noutputs / ncols))

  ma = abs(activations).max()

  plt.subplots(nrows,ncols,figsize = (12, 3*nrows))

  for i in range(noutputs):
      plt.subplot(nrows,ncols,i+1)
      #plt.imshow(activations[0,:,:,i], vmin=-ma, vmax=ma, cmap='bwr')
      plt.imshow(activations[0,:,:,i], cmap='viridis')
      plt.xticks(())
      plt.yticks(())
      plt.title('output kernel %d' % i, fontsize=10)

"""#######################################################################################################


Función 'show_outputs_layers()': 

Muestra las salidas de diferentes capas de un modelo intermedio

* Argumentos:
      - model:  modelo intermedio con varias capas
      - activations: las activaciones que nos devuelve el model.predict() del modelo intermedio
"""

def show_outputs_layers(model,activations):

  # These are the names of the layers, so can have them as part of our plot
  layer_names = []
  for layer in model.layers[1:len(model.layers)]:#hacemos una lista con los nombres de las capas 
      layer_names.append(layer.name)

  images_per_row = 16

  # Now let's display our feature maps
  for layer_name, layer_activation in zip(layer_names, activations):
      # This is the number of features in the feature map
      n_features = layer_activation.shape[-1]

      # The feature map has shape (1, size, size, n_features)
      size = layer_activation.shape[1]

      # We will tile the activation channels in this matrix
      n_cols = n_features // images_per_row
      display_grid = np.zeros((size * n_cols, images_per_row * size))

      # We'll tile each filter into this big horizontal grid
      for col in range(n_cols):
          for row in range(images_per_row):
              channel_image = layer_activation[0,
                                              :, :,
                                              col * images_per_row + row]
              # Post-process the feature to make it visually palatable
              channel_image -= channel_image.mean()
              channel_image /= channel_image.std()
              channel_image *= 64
              channel_image += 128
              channel_image = np.clip(channel_image, 0, 255).astype('uint8')
              display_grid[col * size : (col + 1) * size,
                          row * size : (row + 1) * size] = channel_image

      # Display the grid
      scale = 1. / size
      plt.figure(figsize=(scale * display_grid.shape[1],scale * display_grid.shape[0]))
      plt.title(layer_name)
      plt.grid(False)
      plt.xticks([])
      plt.yticks([])
      plt.imshow(display_grid, aspect='auto', cmap='viridis')

"""#######################################################################################################


Función 'find_ind_last_conv2D()': 

Obtiene el indice de la ultima capa convolucional

* Argumentos:
      - model:  modelo original entrenado

* Devolución:
      - ind_last_conv2D_layer:  indice de la última capa convolucional del modelo

"""

def find_ind_last_conv2D(model):

    ind_last_conv2D_layer = None
    
    for i,x in enumerate(model.layers):

        if x.__class__.__name__ == "Conv2D":
            ind_last_conv2D_layer = i

    return ind_last_conv2D_layer

"""#######################################################################################################


Función 'show_heatmap()': 

Muestra la imagen que se le pasa , su heatmap y el heatmap superpuesto en la imagen

* Argumentos:
      - model:  modelo original entrenado
      - im:  imagen de la cual mostrar el heatmap
      - dict_classes: diccionario (key='numero codificado' , value='nombre de la clase')
"""

def show_heatmap(model, im, dict_classes):
  
    #np.seterr(divide='ignore', invalid='ignore')
    imag = np.expand_dims(im, axis=0) # de 1 imagen pasamos a 1 conjunto de 1 imagen
        
    # The is the output feature map of the last convolutional layer
    last_conv_layer = model.layers[find_ind_last_conv2D(model)]
    # last_conv_layer=model.layers[-8]
    # This is the gradient of the "benign" class with regard to
    # the output feature map of last convolutional layer
    with tf.GradientTape() as tape:
        aux = model.output
        #aux = model.layers[-2].output # salida de la última capa densa antes de softmax

        iterate = tf.keras.models.Model([model.inputs], [aux, last_conv_layer.output])
        model_out, last_conv_layer = iterate(imag)
        class_out = model_out[:, np.argmax(model_out[0])]
        grads = tape.gradient(class_out, last_conv_layer)

        # mean intensity of the gradient over a specific feature map channel:
        pooled_grads = K.mean(grads, axis=(0, 1, 2))
    
    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)    
    heatmap = np.maximum(heatmap, 0) # se quitan los negativos (se ponen a 0)
    
    #print(np.max(heatmap))
    heatmap /= np.max(heatmap) # se normaliza entre 0 y 1
    #heatmap = heatmap/(np.max(heatmap)+0.0000000001) # se normaliza entre 0 y 1   
    #print(np.max(heatmap))
    heatmap = heatmap[0] # pasamos de 1 conjunto de 1 heatmap a 1 heatmap
    
    # We use cv2 to load the original image
    #img = cv2.imread(img_path)
    img = imag[0]
    
    img = np.zeros((im.shape[0],im.shape[1],3))
#    print(im.shape, imag.shape)
    for i in range(3):
        img[:,:,i] = imag[0,:,:,0]

    
    # We resize the heatmap to have the same size as the original image
    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
    
    # We convert the heatmap to RGB
    heatmap = np.uint8(255 * heatmap)
    
    # We apply the heatmap to the original image
    #heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET) / 255
    #heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_BONE) / 255
    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_HOT) / 255
    
    
    # 0.4 here is a heatmap intensity factor
    superimposed_img = heatmap * 0.5 + 0.5*im
    #print(heatmap.min(), heatmap.max(), heatmap.mean(), heatmap.std())
    #print(img.min(), img.max(), img.mean(), img.std())
    #print(superimposed_img.min(),  superimposed_img.max(),
    #      superimposed_img.mean(), superimposed_img.std())
    
    plt.figure(figsize=(15,5))
    plt.subplot(1,3,1)
    plt.imshow(im, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])
    plt.subplot(1,3,2)
    plt.imshow(heatmap, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])
    plt.subplot(1,3,3)
    plt.imshow(superimposed_img, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])
    plt.show()
  

    p = model.predict(imag)[0]
    cadena = ""
    for i in range(len(dict_classes)):
      cadena = cadena + "  {}: {}% ".format(dict_classes[i], int(100*p[i]))
    print(cadena) 
    print("\n\n")

    #return heatmap, superimposed_img