# -*- coding: utf-8 -*-
"""class_model_train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KFcH8BGigW8PebEEXIKD1HBSjgJmSFaU

#Librería con la clase para la construcción del modelo y su entrenamiento.
#Dispone también de otras funciones para la evaluación de modelos.
"""

import tensorflow as tf

from keras.models import Sequential,Model
from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D, Reshape, Conv2D, MaxPooling2D, Input
from keras import backend as K
from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau

import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, precision_recall_curve,auc, accuracy_score
#import plotly.express as px
from tensorflow.keras.applications import VGG16 #,VGG19,ResNet50,EfficientNetB0,MobileNetV2

"""#######################################################################################################


Class Model_VGG16()

Clase para construir el modelo y entrenarlo. Se construye un modelo VGG16 haciendo Transfer Learning donde se puede configurar las capas en la etapa clasificador y las capas que se queire que sean entrenables en la etapa de extracción de características.

+ Constructor:
    * Argumentos:
            - img_shape: tamaño de la imagen con el número de canales incluido(int,int,int)
            - layers: lista con el número de neuronas en cada capa Dense de la etapa clasificadora
            - nclasses: numero de clases, unidades de salida en la última capa (int)
            - optimizer: el optimizador a usar (tensorflow.python.keras.optimizer_v2)
            - loss: tipo de funcón de perdidas (string)
            - num_trainable: numero de capas que se quiere que sean entrenables en la etapa clasificadora. El modelo se descarga sin la etapa clasificadora y se empieza a contar desde la última capa. (int)

+ Función '_build_model(self,model)': se llama desde el propio constructor y crea el modelo.

+ Función '_trainable_layers(self)': se llama desde la función build_model para hacer entrenables solos las capas especificadas.

+ Función 'train_model(self)': función para entrenar el modelo. Se llama con el objeto de la clase instanciado.

    * Argumentos:
            - train_generator: generador del conjunto de entrenamiento
            - epochs: número de épocas de entrenamiento
            - validation_generator: generador del conjunto de validación

    * Devolución:
            - history: historial de entrenamiento

"""

class Model_VGG16():
    
    def __init__(self,img_shape,layers,nclasses,optimizer,loss,num_trainable):

      self.img_shape=img_shape
      self.layers=layers
      self.nclasses=nclasses
      self.optimizer=optimizer
      self.loss=loss
      self.num_trainable=num_trainable
      self.model_vgg16=self._build_model()
      self.model_vgg16.compile(loss=self.loss, optimizer=self.optimizer,metrics=["accuracy"])
      self.model_vgg16.summary()

    def _build_model(self):

      self.model_keras = VGG16(weights="imagenet", include_top=False,input_shape=self.img_shape)

      self._trainable_layers()

      input_layer = self.model_keras.layers[0]
      last_layer = self.model_keras.layers[-1]

      x = Flatten()(last_layer.output)
      x = Dropout(0.5)(x)

      for u in self.layers: 
      
        x = Dense(units=u,activation="relu")(x)
        x = Dropout(0.5)(x)


      final_layer = Dense(units=self.nclasses,activation="softmax")(x)#metemos nuestra capa de clasificacion con las 6 salidas para nuestro problema

      model = Model(inputs=input_layer.output, outputs=final_layer, name="VGG16")

      return model


    def _trainable_layers(self):

      self.model_keras.trainable=False
      for i in range(1,self.num_trainable+1):
        self.model_keras.layers[-i].trainable=True
      

    def train_model(self,train_generator,epochs,validation_generator):

      checkpoint = ModelCheckpoint("best_model.h5",monitor="val_accuracy",save_best_only=True,mode="auto",verbose=1)
      #earlystop = EarlyStopping(monitor="val_accuracy",patience=5,mode="auto",verbose=1)
      reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001, mode = 'auto', verbose = 1)

      list_callbacks=[checkpoint,reduce_lr]#earlystop

      history = self.model_vgg16.fit(train_generator,epochs=epochs,validation_data = validation_generator,verbose=1,callbacks=list_callbacks)

      return history

"""#######################################################################################################


Función 'plot_history()': 

Para plotear el progreso del entrenamiento del modelo

* Argumentos:
      - hist:  la función de entrenamiento del modelo nos devuelve un objeto history ('tensorflow.python.keras.callbacks.History'). A la función le pasamos el diccionario (history.history) 
"""

def plot_history(hist):

  plt.style.use("ggplot")
  plt.figure(figsize=(12,6))

  epochs = range(1,len(hist["accuracy"])+1)

  plt.subplot(1,2,1)
  plt.plot(epochs,hist["accuracy"],'go-')
  plt.plot(epochs,hist["val_accuracy"],'ro-')
  plt.title("Model Accuracy")
  plt.xlabel("Epochs")
  plt.ylabel("Accuracy")
  plt.legend(['Train','Val'],loc = "upper left")

  plt.subplot(1,2,2)
  plt.plot(epochs,hist["loss"],'go-')
  plt.plot(epochs,hist["val_loss"],'ro-')
  plt.title("Model Loss")
  plt.xlabel("Epochs")
  plt.ylabel("Loss")
  plt.legend(['Train','Val'],loc = "upper left")

  plt.show()

"""#######################################################################################################


Función 'evaluate_model_accuracy()':

Para evaluar el modelo sobre un conjunto de entrenamiento

* Argumentos:
      - model:  modelo para evaluar 
      - generator:  generador de un conjunto de datos
      - type_set:  conjunto de entrenamiento (string)
"""

def evaluate_model_accuracy(model,generator,type_set):

  scores = model.evaluate(generator)
  print(type_set,' loss    :', scores[0])
  print(type_set,' accuracy:', scores[1])
  print()

"""#######################################################################################################


Función 'predict_model()':

Otra función para evaluar el modelo sobre un conjunto de entrenamiento. Obtenemos más métricas y por cada clase.

* Argumentos:
      - model:  modelo para evaluar 
      - generator:  generador de un conjunto de datos

* Devolución:
      - y_pred_proba:  probabilidades de la predicción 

"""

def predict_model(model,generator):

  y_real = generator.classes
  y_pred_proba = model.predict(generator)
  # preds_max = np.argmax(y_pred_proba, axis = 1)
  # print(classification_report(y_real, preds_max))

  return y_pred_proba

"""#######################################################################################################


Función 'confusion_matrix_model()':

Para dibujar la matriz de confusión.

* Argumentos:
      - classes:  lista con las clases 
      - dict_indices:  diccionario (key='nombre clase' , value='numero codificado')
      - probabilities: probabilidades obtenidas con el .predict
      - threshold:  umbral para la clase positiva. Si es igual a cero se tratará como problema multiclase
"""

def confusion_matrix_model(classes,dict_indices,probabilities,threshold):

  if threshold==0:
    preds_max = np.argmax(probabilities, axis = 1)
    conmatrix_rf = confusion_matrix(classes, preds_max)
  else:
    conmatrix_rf=confusion_matrix(classes,probabilities[:,1]>threshold)

 
  plt.subplots(figsize = (10, 8))
  sns.heatmap(conmatrix_rf,  cmap = 'Blues', annot = True, fmt = 'd')
  plt.xticks(ticks = list(dict_indices.values()), labels = list(dict_indices.keys()), fontsize = 15, rotation = 45)
  plt.yticks(ticks = list(dict_indices.values()), labels = list(dict_indices.keys()), fontsize = 15, rotation = 45)
  plt.xlabel('Predicted', fontsize = 18)
  plt.ylabel('True Label', fontsize = 18)
  plt.title('Confusion Matrix', fontsize = 22)
  #plt.savefig(parent_dir + 'figures/model_report_confusion_matrix')
  plt.show()

"""#######################################################################################################


Función 'curve_ROC()': 

Dibuja dos curvas:
 -  Curva ROC y su valor bajo de la curva.
 -  Curva precisión recall y su valor bajo de la curva

* Argumentos:
      - classes:  lista con las clases 
      - dict_indices:  diccionario (key='nombre clase' , value='numero codificado')
      - probabilities: probabilidades obtenidas con el .predict
      
"""

def curve_ROC(classes,dict_indices,probabilities):

    y_hat=probabilities[:,1]
    fpr, tpr, thresholds = roc_curve(classes, y_hat, drop_intermediate=False)
    df_roc = pd.DataFrame({'fpr':fpr, 'tpr':tpr, 'threshold':thresholds})

    print('AUC: ',roc_auc_score(classes, y_hat))
    
    #para sacar el mejor umbral
    #gmeans = np.sqrt(tpr * (1-fpr))
    #ix = np.argmax(gmeans)
    #print('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))
    #tambien se puede hacer asi
    J=tpr-fpr
    ix = np.argmax(J)
    print('Best Threshold=%f, J=%.3f' % (thresholds[ix], J[ix]))
    
    plt.plot([0,1], [0,1], linestyle='--', label='No Skill')
    plt.plot(fpr, tpr, marker='.', label='Model')
    plt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')
    
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend()
    
    plt.show()
    
    #Dibujamos la curva ROC de otra forma que nos permite ir moviendonos sobre ella
    # fig = px.line(df_roc, x='fpr', y='tpr', hover_data=['threshold'])
    # fig.show()


    precision, recall, thresholds = precision_recall_curve(classes, y_hat)
    # convert to f score
    fscore = (2 * precision * recall) / (precision + recall)
    where_are_NaNs = np.isnan(fscore)
    fscore[where_are_NaNs] = 0
    # locate the index of the largest f score
    ix = np.argmax(fscore)
    
    print('AUC: ',auc(recall,precision))
    print('Best Threshold=%f, Precision=%.3f, Recall=%.3f, F-Score=%.3f' % (thresholds[ix],precision[ix],recall[ix],fscore[ix]))
    # plot the roc curve for the model
    no_skill = classes.count(1) / len(classes)
    plt.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill')
    plt.plot(recall, precision, marker='.', label='Logistic')
    plt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best')
    # axis labels
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.legend()
    # show the plot
    plt.show()